# tpd_field_checker.py

import os
import pandas as pd

# ---------------------------
# Configuration
# ---------------------------
RUN_CSV_PATH    = r"C:\Input\Run.csv"
FILES_DIRECTORY = r"C:\Files\Located"
OUTPUT_DIRECTORY = os.path.join(FILES_DIRECTORY, "Output")

# Prepare output directory: create if missing, else clear existing files
if not os.path.exists(OUTPUT_DIRECTORY):
    os.makedirs(OUTPUT_DIRECTORY)
else:
    for fn in os.listdir(OUTPUT_DIRECTORY):
        fp = os.path.join(OUTPUT_DIRECTORY, fn)
        if os.path.isfile(fp):
            try:
                os.remove(fp)
            except Exception as e:
                print(f"Warning: could not remove {fp}: {e}")

# ---------------------------
# Read Run.csv and extract mappings
# ---------------------------
def read_run_csv(path):
    try:
        df = pd.read_csv(path, header=None, low_memory=False)
        return df
    except Exception as e:
        print(f"Error reading Run.csv: {e}")
        return None

def parse_run_df(df):
    # TPD fields in column B (index 1), rows 2 onward
    tpd_fields = df.iloc[1:, 1].dropna().astype(str).tolist()

    # Headers in row 1, columns D onward (index 3+)
    raw_headers = df.iloc[0, 3:]
    # Actual filenames in row 2, columns D onward
    raw_fnames  = df.iloc[1, 3:]

    # Build a mask for truly non‐empty filenames
    mask = raw_fnames.notna() & (raw_fnames.astype(str).str.strip() != "")
    headers   = raw_headers[mask].astype(str).tolist()
    file_names = raw_fnames[mask].astype(str).tolist()

    # Map header → filename
    file_map = dict(zip(headers, file_names))
    return tpd_fields, file_map

# ---------------------------
# Evaluate a single CSV file
# ---------------------------
def evaluate_file(full_path, tpd_fields):
    df = pd.read_csv(full_path, low_memory=False)
    total_rows = df.shape[0]  # count of data rows

    results = []
    for field in tpd_fields:
        if field in df.columns:
            # Drop genuine NaNs, then drop any empty‐string cells
            non_blank = df[field].dropna()
            non_blank = non_blank[non_blank.astype(str).str.strip() != ""]
            cnt = non_blank.shape[0]

            if cnt == total_rows:
                results.append("Included")
            elif cnt > 0:
                results.append("Partial")
            else:
                results.append("All Blank")
        else:
            results.append("Field Missing")
    return results

# ---------------------------
# Save results for a file
# ---------------------------
def save_results(file_name, tpd_fields, results):
    output_path = os.path.join(OUTPUT_DIRECTORY, file_name)
    df_out = pd.DataFrame({
        "TPD Field Name": tpd_fields,
        "Status":         results,
    })
    df_out.to_csv(output_path, index=False)

# ---------------------------
# Main
# ---------------------------
def main():
    df_run = read_run_csv(RUN_CSV_PATH)
    if df_run is None:
        return

    tpd_fields, file_map = parse_run_df(df_run)
    if not file_map:
        print("No files specified in row 2 of Run.csv.")
        return

    for header, fname in file_map.items():
        full_path = os.path.join(FILES_DIRECTORY, fname)
        if not os.path.exists(full_path):
            print(f"Missing file for header '{header}': {fname}")
            continue
        results = evaluate_file(full_path, tpd_fields)
        save_results(fname, tpd_fields, results)
        print(f"Results written for file: {fname}")

if __name__ == "__main__":
    main()
