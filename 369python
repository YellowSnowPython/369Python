# tpd_field_checker_step4.py

import os
import pandas as pd
from datetime import datetime

# ---------------------------
# Configuration
# ---------------------------
RUN_CSV_PATH    = r"C:\Input\Run.csv"
FILES_DIRECTORY = r"C:\Files\Located"
OUTPUT_DIRECTORY = r"C:\Files\Located\Output"
DATE_SUFFIX     = datetime.now().strftime("%Y-%m-%d")

# ---------------------------
# Step 1: Read Run.csv
# ---------------------------
def read_run_csv(path):
    """
    Reads Run.csv without assuming a header. Returns DataFrame or None.
    """
    try:
        df = pd.read_csv(path, header=None, low_memory=False)
        print(f"Loaded Run.csv: {df.shape[0]} rows Ã— {df.shape[1]} cols")
        return df
    except Exception as e:
        print(f"Error reading {path}: {e}")
        return None

# ---------------------------
# Step 2: Parse Run.csv
# ---------------------------
def parse_run_df(df):
    """
    Extracts:
      - tpd_fields: list of field names from column B (rows 2+)
      - file_map: dict mapping header name (D1+) to actual filename (D2+);
        if filename cell is blank, fallback to header name (with .csv extension if missing)
      - field_mapping: DataFrame mapping tpd_fields to CSV column names (from rows 2+, cols D+)
    """
    # TPD fields from column B (index 1), rows 2+ (iloc[1:,1])
    tpd_fields = df.iloc[1:, 1].dropna().astype(str).tolist()
    print(f"TPD fields ({len(tpd_fields)}): {tpd_fields}")

    # Headers from row 1 (D1+) and filenames from row 2 (D2+)
    headers = df.iloc[0, 3:].astype(str).tolist()
    filenames = df.iloc[1, 3:].astype(str).tolist()

    # Build file_map with fallback: header if filename empty or 'nan'
    file_map = {}
    for hdr, fn in zip(headers, filenames):
        fn_clean = fn.strip() if isinstance(fn, str) else ''
        if not fn_clean or fn_clean.lower() == 'nan':
            # fallback to header name
            fn_clean = hdr if hdr.lower().endswith('.csv') else f"{hdr}.csv"
        file_map[hdr] = fn_clean
    print(f"File map ({len(file_map)}): {file_map}")

    # Build field mapping from rows 2+ and cols D+
    mapping_df = df.iloc[1:1+len(tpd_fields), 3:3+len(headers)].copy()
    mapping_df.columns = headers
    mapping_df.index = tpd_fields
    print("Field mapping sample:")
    print(mapping_df.head())

    return tpd_fields, file_map, mapping_df

# ---------------------------
# Step 3: Evaluate each file
# ---------------------------
def evaluate_file(header, tpd_fields, file_map, field_mapping):
    """
    For a given header, opens its mapped file and checks each TPD field.
    Returns list of statuses.
    """
    filename = file_map.get(header)
    path = os.path.join(FILES_DIRECTORY, filename)
    if not os.path.exists(path):
        print(f"Missing file for header '{header}': {path}")
        return ["Missing File"] * len(tpd_fields)

    df = pd.read_csv(path, low_memory=False)
    total = df.shape[0] - 1  # excluding header row
    results = []
    for field in tpd_fields:
        # get column mapping or fallback to header name
        col = None
        if header in field_mapping.columns:
            col = field_mapping.at[field, header]
        if pd.isna(col) or not isinstance(col, str) or not col.strip():
            # fallback to header as column name
            col = header
        # evaluate
        if col not in df.columns:
            results.append("Field Missing")
        else:
            filled = df[col].dropna().shape[0]
            if filled == total:
                results.append("Included")
            elif filled > 0:
                results.append("Partial")
            else:
                results.append("All Blank")
    return results

# ---------------------------
# Step 4: Write results
# ---------------------------
def save_result_csv(header, tpd_fields, results):
    os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)
    out_file = os.path.join(OUTPUT_DIRECTORY, f"{DATE_SUFFIX} - {header}.csv")
    pd.DataFrame({
        "TPD Field Name": tpd_fields,
        "Result":        results
    }).to_csv(out_file, index=False)
    print(f"Saved results to {out_file}")

# ---------------------------
# Main
# ---------------------------
def main():
    df = read_run_csv(RUN_CSV_PATH)
    if df is None:
        print("Failed to load Run.csv. Exiting.")
        return

    tpd_fields, file_map, field_mapping = parse_run_df(df)
    print("\nEvaluating files...")
    for header in file_map.keys():
        print(f"\n== {header} ==")
        results = evaluate_file(header, tpd_fields, file_map, field_mapping)
        for fld, res in zip(tpd_fields, results):
            print(f"  {fld}: {res}")
        save_result_csv(header, tpd_fields, results)

if __name__ == "__main__":
    main()

